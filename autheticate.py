import os
import torch
import numpy as np
import librosa
import hashlib
import hmac
import secrets
import time
import json
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import base64
from collections import defaultdict

# –ò–º–ø–æ—Ä—Ç –≤–∞—à–∏—Ö –º–æ–¥—É–ª–µ–π
from model import VoiceAuthCNN
from dataset import VoiceDataset
from evaluate import evaluate_model

class VoiceAuthenticator:
    def __init__(self, master_key=None):
        if master_key is None:
            self.master_key = Fernet.generate_key()
        else:
            self.master_key = master_key
        self.cipher = Fernet(self.master_key)
    
    def create_voice_hash(self, voice_features, user_salt=None):
        """–°–æ–∑–¥–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ö–µ—à –≥–æ–ª–æ—Å–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if user_salt is None:
            user_salt = secrets.token_bytes(32)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –±–∞–π—Ç—ã
        if isinstance(voice_features, torch.Tensor):
            features_bytes = voice_features.cpu().numpy().tobytes()
        else:
            features_bytes = voice_features.tobytes()
        
        # –°–æ–∑–¥–∞–µ–º —Ö–µ—à —Å —Å–æ–ª—å—é
        voice_hash = hashlib.pbkdf2_hmac(
            'sha256', 
            features_bytes, 
            user_salt, 
            100000  # iterations
        )
        
        return voice_hash, user_salt
    
    def encrypt_voice_template(self, voice_features):
        """–®–∏—Ñ—Ä—É–µ—Ç —à–∞–±–ª–æ–Ω –≥–æ–ª–æ—Å–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        if isinstance(voice_features, torch.Tensor):
            features_bytes = voice_features.cpu().numpy().tobytes()
        else:
            features_bytes = voice_features.tobytes()
            
        encrypted = self.cipher.encrypt(features_bytes)
        return encrypted
    
    def decrypt_voice_template(self, encrypted_template, shape):
        """–†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ—Ç —à–∞–±–ª–æ–Ω –≥–æ–ª–æ—Å–∞"""
        decrypted_bytes = self.cipher.decrypt(encrypted_template)
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ numpy array
        features = np.frombuffer(decrypted_bytes, dtype=np.float32)
        return features.reshape(shape)


class SecureVoiceAuthSystem:
    def __init__(self, model_path="voice_auth_improved_model.pth", crypto_key=None, db_path="secure_voice_db.json"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        print("üîê Initializing Secure Voice Authentication System...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model_data = torch.load(model_path, map_location=self.device)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
        config = self.model_data['config']
        self.model = VoiceAuthCNN(
            input_features=config['n_mfcc'],
            output_dim=config['output_dim']
        ).to(self.device)
        self.model.load_state_dict(self.model_data['model_state_dict'])
        self.model.eval()
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        self.n_mfcc = config['n_mfcc']
        self.max_len = config['max_len']
        self.sr = 16000
        
        # –°–∏—Å—Ç–µ–º–∞ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
        self.authenticator = VoiceAuthenticator(crypto_key)
        
        # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        self.db_path = db_path
        self.enrolled_users = self._load_database()
        
        # –°–∏—Å—Ç–µ–º–∞ –∑–∞—â–∏—Ç—ã –æ—Ç —Å–ø—É—Ñ–∏–Ω–≥–∞
        self.anti_spoofing = AntiSpoofingAuth()
        
        # –ü–æ—Ä–æ–≥–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        self.auth_threshold = 0.75  # –ú–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ EER
        self.enrollment_threshold = 0.8
        
        print(f"‚úÖ System initialized on {self.device}")
        print(f"üìä Model performance: EER={self.model_data['results']['eer']:.4f}")
        print(f"üë• Enrolled users: {len(self.enrolled_users)}")
    
    def _load_database(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
        if os.path.exists(self.db_path):
            try:
                with open(self.db_path, 'r') as f:
                    data = json.load(f)
                    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64 –¥–∞–Ω–Ω—ã–µ
                    for user_id, user_data in data.items():
                        user_data['hash'] = base64.b64decode(user_data['hash'])
                        user_data['salt'] = base64.b64decode(user_data['salt'])
                        user_data['encrypted_template'] = base64.b64decode(user_data['encrypted_template'])
                    return data
            except Exception as e:
                print(f"‚ö†Ô∏è Error loading database: {e}")
                return {}
        return {}
    
    def _save_database(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
        try:
            # –ö–æ–¥–∏—Ä—É–µ–º binary –¥–∞–Ω–Ω—ã–µ –≤ base64 –¥–ª—è JSON
            encoded_data = {}
            for user_id, user_data in self.enrolled_users.items():
                encoded_data[user_id] = {
                    'hash': base64.b64encode(user_data['hash']).decode('utf-8'),
                    'salt': base64.b64encode(user_data['salt']).decode('utf-8'),
                    'encrypted_template': base64.b64encode(user_data['encrypted_template']).decode('utf-8'),
                    'template_shape': user_data['template_shape'],
                    'enrollment_time': user_data['enrollment_time'],
                    'last_auth': user_data.get('last_auth', 0)
                }
            
            with open(self.db_path, 'w') as f:
                json.dump(encoded_data, f, indent=2)
        except Exception as e:
            print(f"‚ùå Error saving database: {e}")
    
    def _extract_voice_features(self, audio_path):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            y, sr = librosa.load(audio_path, sr=self.sr)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
            if len(y) < self.sr * 0.5:
                min_len = int(self.sr * 0.5)
                if len(y) > 0:
                    y = np.tile(y, (min_len // len(y)) + 1)[:min_len]
                else:
                    return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ dataset.py)
            mfcc = librosa.feature.mfcc(
                y=y, sr=self.sr, n_mfcc=self.n_mfcc,
                n_fft=1024, hop_length=256, win_length=1024
            )
            
            delta_mfcc = librosa.feature.delta(mfcc)
            delta2_mfcc = librosa.feature.delta(mfcc, order=2)
            
            spectral_centroids = librosa.feature.spectral_centroid(
                y=y, sr=self.sr, hop_length=256
            )
            spectral_rolloff = librosa.feature.spectral_rolloff(
                y=y, sr=self.sr, hop_length=256
            )
            zero_crossing_rate = librosa.feature.zero_crossing_rate(
                y, hop_length=256
            )
            
            chroma = librosa.feature.chroma_stft(
                y=y, sr=self.sr, hop_length=256, n_fft=1024
            )
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            features = np.vstack([
                mfcc, delta_mfcc, delta2_mfcc,
                spectral_centroids, spectral_rolloff,
                zero_crossing_rate, chroma
            ])
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–ª–∏–Ω—É
            if features.shape[1] > self.max_len:
                start = (features.shape[1] - self.max_len) // 2
                features = features[:, start:start + self.max_len]
            else:
                pad_width = self.max_len - features.shape[1]
                features = np.pad(features, ((0, 0), (0, pad_width)),
                                mode='constant', constant_values=0)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            features = (features - np.mean(features, axis=1, keepdims=True))
            std = np.std(features, axis=1, keepdims=True)
            features = features / (std + 1e-8)
            features = np.clip(features, -3, 3)
            
            return torch.tensor(features).float().unsqueeze(0).to(self.device)
            
        except Exception as e:
            print(f"‚ùå Error extracting features: {e}")
            return None
    
    def _get_voice_embedding(self, audio_path):
        """–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –≥–æ–ª–æ—Å–∞ –∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞"""
        features = self._extract_voice_features(audio_path)
        if features is None:
            return None
        
        with torch.no_grad():
            embedding = self.model(features)
            return embedding.squeeze(0)  # –£–±–∏—Ä–∞–µ–º batch dimension
    
    def enroll_user(self, user_id, audio_samples):
        """
        –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∞—É–¥–∏–æ—Å—ç–º–ø–ª–æ–≤
        audio_samples: —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        print(f"üë§ Enrolling user: {user_id}")
        
        if len(audio_samples) < 3:
            print("‚ùå Need at least 3 audio samples for enrollment")
            return False
        
        embeddings = []
        for audio_path in audio_samples:
            embedding = self._get_voice_embedding(audio_path)
            if embedding is not None:
                embeddings.append(embedding)
        
        if len(embeddings) < 2:
            print("‚ùå Not enough valid audio samples")
            return False
        
        # –°–æ–∑–¥–∞–µ–º —à–∞–±–ª–æ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–º–µ–¥–∏–∞–Ω–∞ –¥–ª—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏)
        embeddings_tensor = torch.stack(embeddings)
        template = torch.median(embeddings_tensor, dim=0)[0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —à–∞–±–ª–æ–Ω–∞
        similarities = []
        for emb in embeddings:
            sim = torch.cosine_similarity(template.unsqueeze(0), emb.unsqueeze(0))
            similarities.append(sim.item())
        
        avg_similarity = np.mean(similarities)
        if avg_similarity < self.enrollment_threshold:
            print(f"‚ùå Template quality too low: {avg_similarity:.3f}")
            return False
        
        # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ö–µ—à –∏ —à–∏—Ñ—Ä—É–µ–º —à–∞–±–ª–æ–Ω
        voice_hash, salt = self.authenticator.create_voice_hash(template)
        encrypted_template = self.authenticator.encrypt_voice_template(template)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        self.enrolled_users[user_id] = {
            'hash': voice_hash,
            'salt': salt,
            'encrypted_template': encrypted_template,
            'template_shape': template.shape,
            'enrollment_time': time.time(),
            'last_auth': 0
        }
        
        self._save_database()
        print(f"‚úÖ User {user_id} enrolled successfully (quality: {avg_similarity:.3f})")
        return True
    
    def authenticate_user(self, user_id, audio_path, use_anti_spoofing=True):
        """
        –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        print(f"üîç Authenticating user: {user_id}")
        
        if user_id not in self.enrolled_users:
            print("‚ùå User not enrolled")
            return False, 0.0, "User not found"
        
        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑ –∞—É–¥–∏–æ
        test_embedding = self._get_voice_embedding(audio_path)
        if test_embedding is None:
            print("‚ùå Could not extract features from audio")
            return False, 0.0, "Invalid audio"
        
        user_data = self.enrolled_users[user_id]
        
        # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ö–µ—à—É
        test_hash, _ = self.authenticator.create_voice_hash(
            test_embedding, user_data['salt']
        )
        
        # –¢–æ—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É —à–∞–±–ª–æ–Ω–∞
        stored_template = self.authenticator.decrypt_voice_template(
            user_data['encrypted_template'],
            user_data['template_shape']
        )
        stored_template = torch.tensor(stored_template).to(self.device)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        similarity = torch.cosine_similarity(
            test_embedding.unsqueeze(0),
            stored_template.unsqueeze(0)
        ).item()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥
        is_authenticated = similarity >= self.auth_threshold
        
        if is_authenticated:
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
            self.enrolled_users[user_id]['last_auth'] = time.time()
            self._save_database()
            print(f"‚úÖ Authentication successful (similarity: {similarity:.3f})")
            return True, similarity, "Success"
        else:
            print(f"‚ùå Authentication failed (similarity: {similarity:.3f})")
            return False, similarity, "Similarity too low"
    
    def generate_challenge(self, user_id):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤—ã–∑–æ–≤ –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç —Å–ø—É—Ñ–∏–Ω–≥–∞"""
        return self.anti_spoofing.generate_challenge(user_id)
    
    def verify_challenge_response(self, token, audio_path, transcribed_text):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤—ã–∑–æ–≤"""
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç
        text_valid = self.anti_spoofing.verify_challenge_response(
            token, None, transcribed_text
        )
        
        if not text_valid:
            return False, "Challenge failed"
        
        # –ó–∞—Ç–µ–º –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –≥–æ–ª–æ—Å–∞
        return True, "Challenge passed"
    
    def get_user_stats(self, user_id):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if user_id not in self.enrolled_users:
            return None
        
        user_data = self.enrolled_users[user_id]
        return {
            'user_id': user_id,
            'enrolled': time.ctime(user_data['enrollment_time']),
            'last_auth': time.ctime(user_data['last_auth']) if user_data['last_auth'] > 0 else "Never",
            'template_shape': user_data['template_shape']
        }
    
    def list_users(self):
        """–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
        return list(self.enrolled_users.keys())
    
    def delete_user(self, user_id):
        """–£–¥–∞–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ —Å–∏—Å—Ç–µ–º—ã"""
        if user_id in self.enrolled_users:
            del self.enrolled_users[user_id]
            self._save_database()
            print(f"üóëÔ∏è User {user_id} deleted")
            return True
        return False


class AntiSpoofingAuth:
    def __init__(self):
        self.session_tokens = {}
    
    def generate_challenge(self, user_id):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é —Ñ—Ä–∞–∑—É –¥–ª—è –ø—Ä–æ–≥–æ–≤–∞—Ä–∏–≤–∞–Ω–∏—è"""
        words = ["–∞–ª—å—Ñ–∞", "–±–µ—Ç–∞", "–≥–∞–º–º–∞", "–¥–µ–ª—å—Ç–∞", "—ç–ø—Å–∏–ª–æ–Ω", "–∑–µ—Ç–∞", "—Ç–µ—Ç–∞"]
        numbers = [str(secrets.randbelow(100)) for _ in range(2)]
        challenge = " ".join(secrets.sample(words, 2) + numbers)
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω
        token = secrets.token_urlsafe(32)
        self.session_tokens[token] = {
            'user_id': user_id,
            'challenge': challenge,
            'timestamp': time.time(),
            'used': False
        }
        
        return challenge, token
    
    def verify_challenge_response(self, token, voice_features, transcribed_text):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤—ã–∑–æ–≤"""
        if token not in self.session_tokens:
            return False
        
        session = self.session_tokens[token]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è (—Ç–æ–∫–µ–Ω –¥–µ–π—Å—Ç–≤—É–µ—Ç 60 —Å–µ–∫—É–Ω–¥)
        if time.time() - session['timestamp'] > 60:
            del self.session_tokens[token]
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–æ–∫–µ–Ω –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω
        if session['used']:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç
        if transcribed_text.lower().strip() != session['challenge'].lower().strip():
            return False
        
        session['used'] = True
        return True


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã
def demo_secure_voice_auth():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã"""
    print("üé§ SECURE VOICE AUTHENTICATION SYSTEM DEMO")
    print("=" * 50)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
    try:
        auth_system = SecureVoiceAuthSystem(
            model_path="voice_auth_improved_model.pth"
        )
    except Exception as e:
        print(f"‚ùå Could not initialize system: {e}")
        print("Make sure you have run main.py to train the model first!")
        return
    
    # –ü—Ä–∏–º–µ—Ä —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    print("\n1. ENROLLMENT DEMO")
    user_id = "demo_user_001"
    
    # –í —Ä–µ–∞–ª—å–Ω–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –∑–¥–µ—Å—å –±—ã–ª–∏ –±—ã –ø—É—Ç–∏ –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    sample_files = [
        "path/to/user/sample1.wav",
        "path/to/user/sample2.wav",
        "path/to/user/sample3.wav"
    ]
    
    print(f"Enrolling user: {user_id}")
    # enrollment_result = auth_system.enroll_user(user_id, sample_files)
    
    # –ü—Ä–∏–º–µ—Ä –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    print("\n2. AUTHENTICATION DEMO")
    test_audio = "path/to/test/audio.wav"
    # auth_result, similarity, message = auth_system.authenticate_user(user_id, test_audio)
    
    # –ü—Ä–∏–º–µ—Ä —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç —Å–ø—É—Ñ–∏–Ω–≥–∞
    print("\n3. ANTI-SPOOFING DEMO")
    challenge, token = auth_system.generate_challenge(user_id)
    print(f"Challenge: {challenge}")
    print(f"Token: {token[:16]}...")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    print("\n4. USER MANAGEMENT")
    users = auth_system.list_users()
    print(f"Enrolled users: {users}")
    
    for user in users:
        stats = auth_system.get_user_stats(user)
        if stats:
            print(f"User {user}: enrolled {stats['enrolled']}, last auth {stats['last_auth']}")


if __name__ == "__main__":
    demo_secure_voice_auth()
